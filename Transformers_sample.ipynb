{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *  \n",
    "from tensorflow.keras.callbacks import *\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('train_x_df.csv') \n",
    "train_y = pd.read_csv('train_y_df.csv') \n",
    "test_x = pd.read_csv('test_x_df.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7362, 1380, 10), (7362, 120, 10), (529, 1380, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df2d_to_array3d(df_2d):\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    return array_3d\n",
    "\n",
    "\n",
    "x_train = df2d_to_array3d(train_x) \n",
    "y_train = df2d_to_array3d(train_y) \n",
    "x_test = df2d_to_array3d(test_x) \n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.77it/s]\n"
     ]
    }
   ],
   "source": [
    "scaling_values = [] \n",
    "\n",
    "## standardize column by column \n",
    "for i in tqdm(range(x_train.shape[2]), position = 0, leave = True): \n",
    "    full_data = np.concatenate([x_train[:,:,i], y_train[:,:,i]], axis = 1) \n",
    "    mu = np.mean(full_data) \n",
    "    std = np.std(full_data) \n",
    "    x_train[:,:,i] = (x_train[:,:,i] - mu)/std \n",
    "    y_train[:,:,i] = (y_train[:,:,i] - mu)/std\n",
    "    x_test[:,:,i] = (x_test[:,:,i] - mu)/std \n",
    "    scaling_values.append((mu, std))      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_close = y_train[:,:,4] # close index is the 4th column  \n",
    "x_train_close = x_train[:,:,4].reshape((-1,1380)) \n",
    "x_test_close = x_test[:,:,4].reshape((-1,1380))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7362, 1380), (7362, 120), (529, 1380))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_close.shape, y_train_close.shape, x_test_close.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_quantities = [] # either 0 or 1 \n",
    "sell_times = [] # when to sell i.e. when the close price reaches the highest point in the next 2 hours.  \n",
    "\n",
    "for i in range(y_train_close.shape[0]):\n",
    "#    sell_time = np.argmax(y_train_close[i,:])\n",
    "#    sell_times.append(sell_time)\n",
    "    win_count = 0\n",
    "    for t in range(0, len(y_train_close[i])):\n",
    "        if y_train_close[i][t] > x_train_close[i,-1]:\n",
    "            win_count += 1\n",
    "    win_count_threshold = int(len(y_train_close[i])*0.5)\n",
    "    if win_count >= win_count_threshold:\n",
    "        buy_quantities.append(1.0)\n",
    "        sell_time = np.argmax(y_train_close[i,:])\n",
    "        sell_times.append(sell_time)\n",
    "    else:\n",
    "        buy_quantities.append(0.0)\n",
    "        sell_times.append(0)\n",
    "\n",
    "buy_quantities = np.asarray(buy_quantities).reshape((-1,1))\n",
    "sell_times = np.asarray(sell_times).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7362, 1), (7362, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_quantities.shape, sell_times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "early_stopping = 10\n",
    "num_layers = 4\n",
    "dff = 2048 \n",
    "num_heads = 8 \n",
    "dropout_rate = 0.2\n",
    "d_model = 512 \n",
    "target_size_bq = 1\n",
    "target_size_st = 120 \n",
    "timesteps = 1380 \n",
    "base_channel = 8\n",
    "k = 10 # k fold cross validation if possible \n",
    "learning_rate = 0.00005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                            np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look ahead masks prevent the model from looking ahead at future inputs \n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)  \n",
    "        scaled_attention = tf.squeeze(scaled_attention, axis=1)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "                                Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "                                Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "                                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.Model):\n",
    "    def __init__(self, d_model, num_heads, dff, rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)   \n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        \n",
    "    def call(self, x, mask):   \n",
    "        attn, attn_weights_block = self.mha(x, x, x, mask)  \n",
    "        attn = self.dropout1(attn)\n",
    "        out1 = self.layernorm1(attn + x)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2\n",
    "    \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'mha': self.mha, \n",
    "                       'ffn': self.ffn,\n",
    "                       'layernorm1': self.layernorm1,\n",
    "                       'layernorm2': self.layernorm2, \n",
    "                       'dropout1': self.dropout1, \n",
    "                       'dropout2': self.dropout2})  \n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model \n",
    "        self.feature_extract_model = self.cnn_base(base_channel)\n",
    "        self.fc = Dense(d_model, activation='relu')\n",
    "        self.dropout = Dropout(rate)  \n",
    "        self.pos_encoding = positional_encoding(timesteps,self.d_model)\n",
    "        self.enc_layers = [EncoderLayer(self.d_model, num_heads, dff, dropout_rate) for _ in range(self.num_layers)] \n",
    "        self.embedding = Embedding(timesteps, d_model)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1] \n",
    "        x = self.feature_extract_model(x)\n",
    "        x = self.embedding(x)  \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) \n",
    "        x += self.pos_encoding[:,:seq_len,:]   \n",
    "        x = self.fc(x) \n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, mask) \n",
    "        return x  \n",
    "    \n",
    "    def cnn_base(self, base_channel=8):\n",
    "        input_layer = tf.keras.layers.Input(shape=(1380, 10))\n",
    "        \n",
    "        x = Conv1D(base_channel*2, 3 , activation='relu', padding='same')(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D()(x)   \n",
    "            \n",
    "        x = Conv1D(base_channel*4, 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "\n",
    "        x = Conv1D(base_channel*8, 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "\n",
    "        x = Conv1D(base_channel*16, 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "\n",
    "        x = Conv1D(base_channel*32, 3, activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "\n",
    "        output_layer = Conv1D(base_channel*64, 3, activation='relu', padding='same')(x)\n",
    "        \n",
    "        return Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'num_layers': self.num_layers, \n",
    "                       'd_model': self.d_model,\n",
    "                       'feature_extract_model': self.feature_extract_model,\n",
    "                       'fc': self.fc, \n",
    "                       'dropout': self.dropout, \n",
    "                       'pos_encoding': self.pos_encoding, \n",
    "                       'enc_layers': self.enc_layers})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2) \n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3 \n",
    "    \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'mha1': self.mha1, \n",
    "                       'mha2': self.mha2,\n",
    "                       'ffn': self.ffn,\n",
    "                       'layernorm1': self.layernorm1, \n",
    "                       'layernorm2': self.layernorm2, \n",
    "                       'pos_encoding': self.pos_encoding, \n",
    "                       'layernorm3': self.layernorm3, \n",
    "                       'dropout1': self.dropout1,\n",
    "                       'dropout2': self.dropout2,\n",
    "                       'dropout3': self.dropout3})\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_size, maximum_position_encoding=1500, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "        return x\n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'d_model': self.d_model, \n",
    "                       'num_layers': self.num_layers,\n",
    "                       'embedding': self.embedding,\n",
    "                       'pos_encoding': self.pos_encoding, \n",
    "                       'dec_layers': self.dec_layers, \n",
    "                       'dropout': self.dropout})\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer for sell times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 1380\n",
    "\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''Calculate linear and periodic time features'''\n",
    "        x = tf.math.reduce_mean(x[:,:,:10], axis=-1) \n",
    "        time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    \n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "    \n",
    "        self.key = Dense(self.d_k, \n",
    "                     input_shape=input_shape, \n",
    "                     kernel_initializer='glorot_uniform', \n",
    "                     bias_initializer='glorot_uniform')\n",
    "    \n",
    "        self.value = Dense(self.d_v, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "    \n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.attn_heads = list()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        for n in range(self.n_heads):\n",
    "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
    "    \n",
    "        self.linear = Dense(input_shape[0][-1], \n",
    "                        input_shape=input_shape, \n",
    "                        kernel_initializer='glorot_uniform', \n",
    "                        bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = tf.concat(attn, axis=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.attn_heads = []\n",
    "        self.dropout_rate = dropout \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "        self.attn_dropout = Dropout(self.dropout_rate)\n",
    "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "        self.ff_dropout = Dropout(self.dropout_rate)\n",
    "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq) \n",
    "        attn_layer = self.attn_multi(inputs) \n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)  \n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer \n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'d_k': self.d_k,\n",
    "                   'd_v': self.d_v,\n",
    "                   'n_heads': self.n_heads,\n",
    "                   'ff_dim': self.ff_dim,\n",
    "                   'attn_heads': self.attn_heads,\n",
    "                   'dropout_rate': self.dropout_rate})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(target_size, activation): \n",
    "    time_embedding = Time2Vector(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "    inputs = Input(shape=(seq_len, 10))\n",
    "    x = time_embedding(inputs)\n",
    "    x = Concatenate(axis=-1)([inputs, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(target_size, activation=activation)(x)\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1380, 10)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector (Time2Vector)      (None, 1380, 2)      5520        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1380, 12)     0           input_1[0][0]                    \n",
      "                                                                 time2_vector[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 1380, 12)     163144      concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_1 (Transfor (None, 1380, 12)     163144      transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "                                                                 transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_2 (Transfor (None, 1380, 12)     163144      transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "                                                                 transformer_encoder_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 1380)         0           transformer_encoder_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1380)         0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          353536      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          30840       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 879,328\n",
      "Trainable params: 879,328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(120, 'softmax')  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'st_transEncoder_epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.8)\n",
    "checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
    "history = model.fit(x_train,\n",
    "                    sell_times,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 4,\n",
    "                    validation_split = 0.2, \n",
    "                    callbacks = [learning_rate_reduction, checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer for buy quantity\n",
    "\n",
    "- just modify the code for above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
