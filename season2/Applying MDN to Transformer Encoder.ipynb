{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *  \n",
    "from tensorflow.keras.callbacks import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow_probability import distributions as tfd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and utility functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10572180, 12), (919320, 12), (738300, 12), (535, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## season 2 dataframes \n",
    "train_x_2 = pd.read_csv('train_x_df.csv')\n",
    "train_y_2 = pd.read_csv('train_y_df.csv') \n",
    "test_x_2 = pd.read_csv('test_x_df.csv') \n",
    "submission = pd.read_csv('sample_submission.csv') \n",
    "\n",
    "train_x_2.shape, train_y_2.shape, test_x_2.shape, submission.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7661, 1380, 10), (7661, 120, 10), (535, 1380, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df2d_to_array3d(df_2d):\n",
    "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
    "    time_size = len(df_2d.time.value_counts())\n",
    "    sample_size = len(df_2d.sample_id.value_counts())\n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
    "    return array_3d\n",
    "\n",
    "\n",
    "x_train = df2d_to_array3d(train_x_2) \n",
    "y_train = df2d_to_array3d(train_y_2) \n",
    "x_test = df2d_to_array3d(test_x_2) \n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(x_series, y_series, y_predicted):\n",
    "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n",
    "             y_series, label = 'actual_series') \n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
    "             y_predicted, label = 'predicted_series') \n",
    "    #plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_series(x_series, y_predicted):\n",
    "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
    "             y_predicted, label = 'predicted_series') \n",
    "    #plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7661, 1500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_close = x_train[:,:,4] \n",
    "y_train_close = y_train[:,:,4] \n",
    "x_test_close = x_test[:,:,4] \n",
    "\n",
    "close_prices = np.concatenate([x_train_close, y_train_close], axis = 1) \n",
    "close_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8\n",
    "\n",
    "close_prices = np.log(close_prices + eps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_close = np.log(x_test_close + eps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "Given time series data (t_1, t_2, ..., tN) predict t{N+K} Here, we let K = 120 and N is a hyperparameter, but we can let it be 60 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7661/7661 [00:09<00:00, 783.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10112520, 60), (10112520,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 120 \n",
    "N = 60 \n",
    "seq_len = 1500 \n",
    "features = 1\n",
    "X = [] \n",
    "Y = [] \n",
    "\n",
    "for j in tqdm(range(close_prices.shape[0]), position = 0, leave = True): \n",
    "    i = 0\n",
    "    while i+N+K < 1500: \n",
    "        X.append(close_prices[j, i:i+N]) \n",
    "        Y.append(close_prices[j, i+N+K]) \n",
    "        i += 1   \n",
    "        \n",
    "        \n",
    "X = np.asarray(X) \n",
    "Y = np.asarray(Y)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10112520, 60, 1), (10112520, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape((-1,N,features)) \n",
    "Y = Y.reshape((-1,features))\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_parameters = 3\n",
    "components = 4\n",
    "\n",
    "def nnelu(input):\n",
    "    \"\"\" Computes the Non-Negative Exponential Linear Unit\n",
    "    \"\"\"\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    \"\"\" Returns an unpacked list of paramter vectors.\n",
    "    \"\"\"\n",
    "    return [parameter_vector[:,i*components:(i+1)*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n",
    "    \n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,       \n",
    "            scale=sigma))\n",
    "    \n",
    "    log_likelihood = gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y\n",
    "    \n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(inputs, node, drop_rate, activation): \n",
    "    attn_output = MultiHeadAttention(num_heads = 2, key_dim = node)(inputs, inputs) \n",
    "    attn_output = Dropout(drop_rate)(attn_output) \n",
    "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output) \n",
    "    ffn_output = Dense(node, activation = activation)(out1) \n",
    "    ffn_output = Dense(node)(ffn_output) \n",
    "    ffn_output = Dropout(drop_rate)(ffn_output)\n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output) \n",
    "    return out2\n",
    "    \n",
    "    \n",
    "def build_transformer(node = 64, activation = 'relu', drop_rate = 0.2, num_layers = 3):  \n",
    "    inputs = Input((N, features)) \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    x = Conv1D(node*2, 5, activation = activation)(bn) \n",
    "    x = MaxPooling1D(3)(x) \n",
    "    x = Dropout(drop_rate)(x) \n",
    "    x = Conv1D(node, 5, activation = activation)(x) \n",
    "    x = MaxPooling1D(3)(x) \n",
    "    x = Dropout(drop_rate)(x) \n",
    "    \n",
    "    positions = tf.range(start=0, limit=x.shape[1], delta=1)\n",
    "    positions = Embedding(input_dim = x.shape[1], output_dim = node)(positions) \n",
    "    x = x + positions \n",
    "    \n",
    "    x = transformer_block(x, node, drop_rate, activation) \n",
    "        \n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(drop_rate)(x)  \n",
    "    \n",
    "    \n",
    "    alpha_v = Dense(components, activation = 'softmax')(x)\n",
    "    mu_v = Dense(components)(x) \n",
    "    sigma_v = Dense(components, activation = 'nnelu')(x)\n",
    "    \n",
    "    outputs = Concatenate()([alpha_v, mu_v, sigma_v])\n",
    "    \n",
    "    model = Model(inputs=inputs,outputs=outputs) \n",
    "    model.compile(loss = gnll_loss, optimizer = 'adam') \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 60, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 1)        4           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 56, 128)      768         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 18, 128)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 18, 128)      0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 14, 64)       41024       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 4, 64)        0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 4, 64)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 4, 64)        0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 4, 64)        33216       tf.__operators__.add_12[0][0]    \n",
      "                                                                 tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 4, 64)        0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 4, 64)        0           tf.__operators__.add_12[0][0]    \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 4, 64)        128         tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4, 64)        4160        layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 4, 64)        4160        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 4, 64)        0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 4, 64)        0           layer_normalization_8[0][0]      \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 4, 64)        128         tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 64)           0           layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 64)           0           global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 12)           0           dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 84,368\n",
      "Trainable params: 84,366\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "284415/284415 [==============================] - 1887s 7ms/step - loss: -2.7836 - val_loss: -3.0229\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -3.02289, saving model to Transformer_MDN_Close_epoch_001_val_-3.023.h5\n",
      "Epoch 2/100\n",
      "117579/284415 [===========>..................] - ETA: 17:27 - loss: -2.8877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284415/284415 [==============================] - 1871s 7ms/step - loss: -2.8881 - val_loss: -2.9714\n",
      "\n",
      "Epoch 00002: val_loss did not improve from -3.02289\n",
      "Epoch 3/100\n",
      "284415/284415 [==============================] - 1866s 7ms/step - loss: -2.8889 - val_loss: -2.9103\n",
      "\n",
      "Epoch 00003: val_loss did not improve from -3.02289\n",
      "Epoch 4/100\n",
      "284415/284415 [==============================] - 1843s 6ms/step - loss: -2.8923 - val_loss: -2.9252\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from -3.02289\n",
      "Epoch 5/100\n",
      "284415/284415 [==============================] - 1825s 6ms/step - loss: -2.9119 - val_loss: -2.9422\n",
      "\n",
      "Epoch 00005: val_loss did not improve from -3.02289\n",
      "Epoch 6/100\n",
      "284415/284415 [==============================] - 1815s 6ms/step - loss: -2.9119 - val_loss: -2.9125\n",
      "\n",
      "Epoch 00006: val_loss did not improve from -3.02289\n",
      "Epoch 7/100\n",
      "284415/284415 [==============================] - 1823s 6ms/step - loss: -2.9136 - val_loss: -2.8384\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from -3.02289\n",
      "Epoch 8/100\n",
      "217563/284415 [=====================>........] - ETA: 6:46 - loss: -2.9226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278871/284415 [============================>.] - ETA: 33s - loss: -2.9226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56475/284415 [====>.........................] - ETA: 23:06 - loss: -2.9240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118052/284415 [===========>..................] - ETA: 16:52 - loss: -2.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180083/284415 [=================>............] - ETA: 10:35 - loss: -2.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282029/284415 [============================>.] - ETA: 14s - loss: -2.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62613/284415 [=====>........................] - ETA: 22:30 - loss: -2.9241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125094/284415 [============>.................] - ETA: 16:09 - loss: -2.9244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186105/284415 [==================>...........] - ETA: 9:58 - loss: -2.9244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248428/284415 [=========================>....] - ETA: 3:39 - loss: -2.9244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284415/284415 [==============================] - 1815s 6ms/step - loss: -2.9244 - val_loss: -2.8772\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from -3.02289\n",
      "Epoch 11/100\n",
      " 26639/284415 [=>............................] - ETA: 26:12 - loss: -2.9260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88147/284415 [========>.....................] - ETA: 19:57 - loss: -2.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193107/284415 [===================>..........] - ETA: 9:16 - loss: -2.9286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265615/284415 [===========================>..] - ETA: 1:54 - loss: -2.9287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'Transformer_MDN_Close_epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5)\n",
    "checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
    "\n",
    "\n",
    "history = model.fit(x=X, \n",
    "                    y=Y, \n",
    "                    batch_size = 32, \n",
    "                    epochs = 100, \n",
    "                    callbacks = [learning_rate_reduction, checkpoint, early_stopping], \n",
    "                    validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 60, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 1)        4           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 56, 128)      768         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 18, 128)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 18, 128)      0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 14, 64)       41024       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 4, 64)        0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 4, 64)        0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 4, 64)        0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 4, 64)        33216       tf.__operators__.add_12[0][0]    \n",
      "                                                                 tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 4, 64)        0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 4, 64)        0           tf.__operators__.add_12[0][0]    \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 4, 64)        128         tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4, 64)        4160        layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 4, 64)        4160        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 4, 64)        0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 4, 64)        0           layer_normalization_8[0][0]      \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 4, 64)        128         tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 64)           0           layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 64)           0           global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 4)            260         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 12)           0           dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 84,368\n",
      "Trainable params: 84,366\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('Transformer_MDN_Close_epoch_001_val_-3.023.h5', custom_objects={'Activation':Activation(nnelu), 'gnll_loss':gnll_loss})\n",
    "\n",
    "best_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 16534.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64200, 60, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to preprocess inputs for prediction \n",
    "X_test = [] \n",
    "for j in tqdm(range(x_test_close.shape[0]), position = 0, leave = True): \n",
    "    for i in range(seq_len-N-K-120, seq_len-N-K):\n",
    "        X_test.append(x_test_close[j, i:i+N])  \n",
    "\n",
    "X_test = np.asarray(X_test).reshape((-1,N,features))\n",
    "\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 12, 120)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = best_model.predict(X_test) \n",
    "\n",
    "predicted = predicted.reshape((-1,12,120)) \n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, mu, sigma = slice_parameter_vectors(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535, 4, 120), (535, 4, 120), (535, 4, 120))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.shape, mu.shape, sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 1567.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(535, 120)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## decide buy quantity and sell time \n",
    "## first get the predicted prices (i.e. mean of each distribution)\n",
    "sell_prices = [] \n",
    "for i in tqdm(range(alpha.shape[0]), position = 0, leave = True): \n",
    "    sample_prices = [] \n",
    "    for j in range(120): \n",
    "        price = 0 \n",
    "        for k in range(components):\n",
    "            price += alpha[i,k,j] * mu[i,k,j]\n",
    "        sample_prices.append(price) \n",
    "    sell_prices.append(sample_prices) \n",
    "    \n",
    "sell_prices = np.asarray(sell_prices) \n",
    "sell_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 828.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(535, 120)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## second, compute the standard deviation of each distribution \n",
    "## note that the mus are stored inside the array sell_prices \n",
    "stdevs = [] \n",
    "for i in tqdm(range(alpha.shape[0]), position = 0, leave = True): \n",
    "    sample_stdevs = [] \n",
    "    for j in range(120): \n",
    "        stdev = 0 \n",
    "        for k in range(components): \n",
    "            stdev += alpha[i,k,j] * (sigma[i,k,j]*sigma[i,k,j] + mu[i,k,j]*mu[i,k,j]) \n",
    "        stdev = stdev - (sell_prices[i,j] * sell_prices[i,j])  \n",
    "        sample_stdevs.append(stdev)\n",
    "    stdevs.append(sample_stdevs) \n",
    "\n",
    "stdevs = np.asarray(stdevs) \n",
    "stdevs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 125648.28it/s]\n"
     ]
    }
   ],
   "source": [
    "## Select the time when the highest mean occurs  \n",
    "## Use Kelly Criterion to decide buy quantity \n",
    "\n",
    "buy_quantities = [] \n",
    "sell_times = [] \n",
    "\n",
    "for i in tqdm(range(sell_prices.shape[0]), position = 0, leave = True): \n",
    "    sell_time = np.argmax(sell_prices[i,:]) \n",
    "    sell_times.append(sell_time) \n",
    "    \n",
    "    buy_price = x_test_close[i,-1]  \n",
    "    returns = sell_prices[i,sell_time] - buy_price   \n",
    "    buy_quantity = returns / (stdevs[i,sell_time] * stdevs[i,sell_time])  \n",
    "    \n",
    "    buy_quantities.append(buy_quantity)  \n",
    "    \n",
    "buy_quantities = np.asarray(buy_quantities) \n",
    "sell_times = np.asarray(sell_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalize buy_quantities \n",
    "scaler = MinMaxScaler() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((535,), (535,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_quantities.shape, sell_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
