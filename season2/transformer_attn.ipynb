{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import * \n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.callbacks import * \n",
    "import tensorflow_addons as tfa\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "import random \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow_probability import distributions as tfd \n",
    "import seaborn as sns \n",
    "import requests\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10572180, 12), (919320, 12), (738300, 12), (535, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_2 = pd.read_csv('train_x_df.csv') \n",
    "train_y_2 = pd.read_csv('train_y_df.csv') \n",
    "test_x_2 = pd.read_csv('test_x_df.csv') \n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv') \n",
    "\n",
    "train_x_2.shape, train_y_2.shape, test_x_2.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7661, 1380, 10), (7661, 120, 10), (535, 1380, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df2d_to_array3d(df_2d): \n",
    "    feature_size = df_2d.iloc[:,2:].shape[1] \n",
    "    time_size = len(df_2d.time.value_counts()) \n",
    "    sample_size = len(df_2d.sample_id.value_counts()) \n",
    "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size]) \n",
    "    return array_3d \n",
    "\n",
    "x_train = df2d_to_array3d(train_x_2) \n",
    "y_train = df2d_to_array3d(train_y_2) \n",
    "x_test = df2d_to_array3d(test_x_2) \n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(x_series, y_series, y_predicted):\n",
    "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n",
    "             y_series, label = 'actual_series') \n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
    "             y_predicted, label = 'predicted_series') \n",
    "    #plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_series(x_series, y_predicted):\n",
    "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
    "    plt.plot(x_series, label = 'input_series')\n",
    "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
    "             y_predicted, label = 'predicted_series') \n",
    "    #plt.axhline(1, c = 'red')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7661, 1500, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = np.concatenate([x_train, y_train], axis = 1) \n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7661, 1500, 4), (7661, 1500, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_data = full_df[:,:,[1,2,3,4]] \n",
    "volume_data = full_df[:,:,[5,6,7,8,9]] \n",
    "\n",
    "price_data.shape, volume_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7661/7661 [00:57<00:00, 132.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10112520, 60, 4), (10112520, 60, 5), (10112520,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 120 \n",
    "N = 60\n",
    "seq_len = 1500 \n",
    "features_price = 4 \n",
    "features_volume = 5 \n",
    "X_price = np.zeros(((seq_len-N-K)*price_data.shape[0], N, features_price))\n",
    "X_volume = np.zeros(((seq_len-N-K)*price_data.shape[0], N, features_volume))\n",
    "Y = np.zeros(((seq_len-N-K)*price_data.shape[0]))\n",
    "\n",
    "cnt = 0 \n",
    "for j in tqdm(range(price_data.shape[0]), position = 0, leave = True): \n",
    "    i = 0\n",
    "    while i+N+K < 1500: \n",
    "        X_price[cnt,:,:] = price_data[j, i:i+N, :] \n",
    "        X_volume[cnt,:,:] = volume_data[j, i:i+N, :] \n",
    "        Y[cnt] = price_data[j, i+N+K, 0] \n",
    "        i += 1   \n",
    "        cnt += 1 \n",
    "        \n",
    "\n",
    "X_price.shape, X_volume.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                              shape=(int(self.seq_len),),\n",
    "                                              initializer='glorot_uniform',\n",
    "                                              trainable=True)\n",
    "    \n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                           shape=(int(self.seq_len),),\n",
    "                                           initializer='glorot_uniform',\n",
    "                                           trainable=True)\n",
    "    \n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                                shape=(int(self.seq_len),),\n",
    "                                                initializer='glorot_uniform',\n",
    "                                                trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                             shape=(int(self.seq_len),),\n",
    "                                             initializer='glorot_uniform',\n",
    "                                             trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''Calculate linear and periodic time features'''\n",
    "        x = tf.math.reduce_mean(x[:,:,:], axis=-1) \n",
    "        time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    \n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(inputs, node, drop_rate, activation): \n",
    "    attn_output = MultiHeadAttention(num_heads = 4, key_dim = node)(inputs, inputs) \n",
    "    attn_output = Dropout(drop_rate)(attn_output)\n",
    "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output) \n",
    "    ffn_output = Dense(node, activation = activation)(out1) \n",
    "    ffn_output = Dense(node)(ffn_output) \n",
    "    ffn_output = Dropout(drop_rate)(ffn_output) \n",
    "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output) \n",
    "    return out2\n",
    "\n",
    "\n",
    "def transformer(inputs, node = 32, activation = 'relu', drop_rate = 0.2, num_layers = 2):\n",
    "    time_embedding = Time2Vector(N) \n",
    "    bn = BatchNormalization()(inputs)\n",
    "    x = time_embedding(bn) \n",
    "    x = Concatenate()([bn, x])  \n",
    "    \n",
    "    x = Conv1D(node, 5, activation = activation, padding = 'same')(x) \n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Dropout(drop_rate)(x) \n",
    "    \n",
    "    x = Conv1D(node*2, 5, activation = activation, padding = 'same')(x) \n",
    "    x = MaxPooling1D()(x) \n",
    "    x = Dropout(drop_rate)(x)   \n",
    "    \n",
    "    positions = tf.range(start=0, limit=x.shape[1], delta=1)  \n",
    "    positions = Embedding(input_dim = x.shape[1], output_dim = node*2)(positions) \n",
    "    x = x + positions \n",
    "    for i in range(num_layers): \n",
    "        x = transformer_block(x, node*2, drop_rate, activation)\n",
    "    return x \n",
    "\n",
    "def build_model(): \n",
    "    price_inputs = Input((N, features_price)) \n",
    "    x_p = transformer(price_inputs) \n",
    "    \n",
    "    volume_inputs = Input((N, features_volume)) \n",
    "    x_v = transformer(volume_inputs) \n",
    "    \n",
    "    attn_p_v = MultiHeadAttention(num_heads=2,key_dim=64)(x_p,x_v) \n",
    "    attn_v_p = MultiHeadAttention(num_heads=2,key_dim=64)(x_v,x_p) \n",
    "    attn = Dropout(0.25)(attn_p_v + attn_v_p)\n",
    "    attn = Dense(32)(attn) \n",
    "    attn = Activation('tanh')(attn) \n",
    "    output = GlobalMaxPooling1D()(attn) \n",
    "    output = Dense(16, activation = 'relu')(output) \n",
    "    output = Dropout(0.25)(output) \n",
    "    output = Dense(1, activation = 'relu')(output)\n",
    "    \n",
    "    model = Model(inputs=[price_inputs, volume_inputs], outputs=output) \n",
    "    model.compile(loss='mape', optimizer = 'adam', metrics=['mse','mae','mape']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 60, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 60, 4)        16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 60, 5)        20          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector (Time2Vector)      (None, 60, 2)        240         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector_1 (Time2Vector)    (None, 60, 2)        240         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60, 6)        0           batch_normalization[0][0]        \n",
      "                                                                 time2_vector[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 7)        0           batch_normalization_1[0][0]      \n",
      "                                                                 time2_vector_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 60, 32)       992         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 60, 32)       1152        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 30, 32)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 30, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 32)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 32)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 64)       10304       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 64)       10304       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 15, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 15, 64)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 15, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 15, 64)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 15, 64)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 15, 64)       66368       tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 15, 64)       66368       tf.__operators__.add_5[0][0]     \n",
      "                                                                 tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 15, 64)       0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 15, 64)       0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 15, 64)       0           tf.__operators__.add[0][0]       \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 15, 64)       0           tf.__operators__.add_5[0][0]     \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 15, 64)       128         tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 15, 64)       128         tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 15, 64)       4160        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 15, 64)       4160        layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 15, 64)       4160        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 15, 64)       4160        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15, 64)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 15, 64)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 15, 64)       0           layer_normalization[0][0]        \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 15, 64)       0           layer_normalization_4[0][0]      \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 15, 64)       128         tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 15, 64)       128         tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 15, 64)       66368       layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 15, 64)       66368       layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 15, 64)       0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 64)       0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 15, 64)       0           layer_normalization_1[0][0]      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 15, 64)       0           layer_normalization_5[0][0]      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 15, 64)       128         tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 15, 64)       128         tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15, 64)       4160        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 15, 64)       4160        layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 15, 64)       4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 15, 64)       4160        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 15, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 15, 64)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 15, 64)       0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 15, 64)       0           layer_normalization_6[0][0]      \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 15, 64)       128         tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 15, 64)       128         tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 15, 64)       33216       layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 15, 64)       33216       layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 15, 64)       0           multi_head_attention_4[0][0]     \n",
      "                                                                 multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 15, 64)       0           tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 15, 32)       2080        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 15, 32)       0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           528         global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            17          dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 392,101\n",
      "Trainable params: 392,083\n",
      "Non-trainable params: 18\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17776/17776 [==============================] - 538s 30ms/step - loss: 4.2310 - mse: 0.0102 - mae: 0.0423 - mape: 4.2310 - val_loss: 0.9990 - val_mse: 5.0076e-04 - val_mae: 0.0101 - val_mape: 0.9990\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.99901, saving model to attn_transformer_price_volume_epoch_001_val_0.999.h5\n",
      "Epoch 2/20\n",
      "17776/17776 [==============================] - 417s 23ms/step - loss: 1.1051 - mse: 3.3496e-04 - mae: 0.0111 - mape: 1.1051 - val_loss: 1.0338 - val_mse: 3.9385e-04 - val_mae: 0.0104 - val_mape: 1.0338\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.99901\n",
      "Epoch 3/20\n",
      "17776/17776 [==============================] - 412s 23ms/step - loss: 1.0970 - mse: 3.2948e-04 - mae: 0.0110 - mape: 1.0970 - val_loss: 1.0566 - val_mse: 4.2862e-04 - val_mae: 0.0106 - val_mape: 1.0566\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.99901\n",
      "Epoch 4/20\n",
      "17776/17776 [==============================] - 412s 23ms/step - loss: 1.0935 - mse: 3.2734e-04 - mae: 0.0109 - mape: 1.0935 - val_loss: 1.0214 - val_mse: 4.0494e-04 - val_mae: 0.0103 - val_mape: 1.0214\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.99901\n",
      "Epoch 5/20\n",
      "17776/17776 [==============================] - 406s 23ms/step - loss: 1.0827 - mse: 3.2071e-04 - mae: 0.0108 - mape: 1.0827 - val_loss: 0.9910 - val_mse: 3.8155e-04 - val_mae: 0.0100 - val_mape: 0.9910\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.99901 to 0.99096, saving model to attn_transformer_price_volume_epoch_005_val_0.991.h5\n",
      "Epoch 6/20\n",
      "17776/17776 [==============================] - 416s 23ms/step - loss: 1.0815 - mse: 3.2040e-04 - mae: 0.0108 - mape: 1.0815 - val_loss: 0.9951 - val_mse: 3.6882e-04 - val_mae: 0.0100 - val_mape: 0.9951\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.99096\n",
      "Epoch 7/20\n",
      " 7177/17776 [===========>..................] - ETA: 3:52 - loss: 1.0797 - mse: 3.1674e-04 - mae: 0.0108 - mape: 1.0797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10690/17776 [=================>............] - ETA: 2:35 - loss: 1.0811 - mse: 3.1800e-04 - mae: 0.0108 - mape: 1.0811"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15620/17776 [=========================>....] - ETA: 47s - loss: 1.0746 - mse: 3.1508e-04 - mae: 0.0107 - mape: 1.0746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 436s 25ms/step - loss: 1.0721 - mse: 3.1164e-04 - mae: 0.0107 - mape: 1.0721 - val_loss: 1.0051 - val_mse: 3.5839e-04 - val_mae: 0.0101 - val_mape: 1.0051\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.99096\n",
      "Epoch 11/20\n",
      " 1053/17776 [>.............................] - ETA: 6:29 - loss: 1.0798 - mse: 3.1717e-04 - mae: 0.0108 - mape: 1.0798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 447s 25ms/step - loss: 1.0735 - mse: 3.1359e-04 - mae: 0.0107 - mape: 1.0735 - val_loss: 1.0503 - val_mse: 3.7938e-04 - val_mae: 0.0106 - val_mape: 1.0503\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.99096\n",
      "Epoch 12/20\n",
      " 4336/17776 [======>.......................] - ETA: 4:55 - loss: 1.0689 - mse: 3.1051e-04 - mae: 0.0107 - mape: 1.0689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 409s 23ms/step - loss: 1.0690 - mse: 3.1087e-04 - mae: 0.0107 - mape: 1.0690 - val_loss: 1.0253 - val_mse: 3.6239e-04 - val_mae: 0.0103 - val_mape: 1.0253\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.99096\n",
      "Epoch 13/20\n",
      "17776/17776 [==============================] - 407s 23ms/step - loss: 1.0694 - mse: 3.1087e-04 - mae: 0.0107 - mape: 1.0694 - val_loss: 1.0093 - val_mse: 3.4862e-04 - val_mae: 0.0101 - val_mape: 1.0093\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.99096\n",
      "Epoch 14/20\n",
      " 2370/17776 [==>...........................] - ETA: 5:32 - loss: 1.0650 - mse: 3.0615e-04 - mae: 0.0107 - mape: 1.0650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 410s 23ms/step - loss: 1.0670 - mse: 3.0936e-04 - mae: 0.0107 - mape: 1.0670 - val_loss: 1.0456 - val_mse: 3.6307e-04 - val_mae: 0.0105 - val_mape: 1.0456\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.99096\n",
      "Epoch 17/20\n",
      " 4875/17776 [=======>......................] - ETA: 4:41 - loss: 1.0662 - mse: 3.0748e-04 - mae: 0.0107 - mape: 1.0662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 407s 23ms/step - loss: 1.0667 - mse: 3.0812e-04 - mae: 0.0107 - mape: 1.0667 - val_loss: 1.0285 - val_mse: 3.5645e-04 - val_mae: 0.0103 - val_mape: 1.0285\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.99096\n",
      "Epoch 18/20\n",
      " 8100/17776 [============>.................] - ETA: 3:32 - loss: 1.0662 - mse: 3.0912e-04 - mae: 0.0107 - mape: 1.0662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 409s 23ms/step - loss: 1.0656 - mse: 3.0856e-04 - mae: 0.0107 - mape: 1.0656 - val_loss: 1.0348 - val_mse: 3.5782e-04 - val_mae: 0.0104 - val_mape: 1.0348\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.99096\n",
      "Epoch 19/20\n",
      "17776/17776 [==============================] - 411s 23ms/step - loss: 1.0648 - mse: 3.0707e-04 - mae: 0.0107 - mape: 1.0648 - val_loss: 1.0409 - val_mse: 3.6213e-04 - val_mae: 0.0105 - val_mape: 1.0409\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.99096\n",
      "Epoch 20/20\n",
      " 1664/17776 [=>............................] - ETA: 5:49 - loss: 1.0646 - mse: 3.0827e-04 - mae: 0.0106 - mape: 1.0646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776/17776 [==============================] - 405s 23ms/step - loss: 1.0651 - mse: 3.0766e-04 - mae: 0.0107 - mape: 1.0651 - val_loss: 1.0351 - val_mse: 3.6018e-04 - val_mae: 0.0104 - val_mape: 1.0351\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.99096\n"
     ]
    }
   ],
   "source": [
    "model_path = 'attn_transformer_price_volume_epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5)\n",
    "checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
    "\n",
    "\n",
    "history = model.fit([X_price, X_volume], \n",
    "                     Y, \n",
    "                     batch_size = 512, \n",
    "                     epochs = 20, \n",
    "                     callbacks = [learning_rate_reduction, checkpoint], \n",
    "                     validation_split = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 60, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 60, 4)        16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 60, 5)        20          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector_2 (Time2Vector)    (None, 60, 2)        240         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector_3 (Time2Vector)    (None, 60, 2)        240         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60, 6)        0           batch_normalization[0][0]        \n",
      "                                                                 time2_vector_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 7)        0           batch_normalization_1[0][0]      \n",
      "                                                                 time2_vector_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 60, 32)       992         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 60, 32)       1152        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 30, 32)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 30, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 32)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 32)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 64)       10304       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 64)       10304       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 15, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 15, 64)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15, 64)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 15, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 15, 64)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 15, 64)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 15, 64)       66368       tf.__operators__.add[0][0]       \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 15, 64)       66368       tf.__operators__.add_5[0][0]     \n",
      "                                                                 tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 15, 64)       0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 15, 64)       0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 15, 64)       0           tf.__operators__.add[0][0]       \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 15, 64)       0           tf.__operators__.add_5[0][0]     \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 15, 64)       128         tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 15, 64)       128         tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 15, 64)       4160        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 15, 64)       4160        layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 15, 64)       4160        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 15, 64)       4160        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15, 64)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 15, 64)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 15, 64)       0           layer_normalization[0][0]        \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 15, 64)       0           layer_normalization_4[0][0]      \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 15, 64)       128         tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 15, 64)       128         tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 15, 64)       66368       layer_normalization_1[0][0]      \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 15, 64)       66368       layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 15, 64)       0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 64)       0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 15, 64)       0           layer_normalization_1[0][0]      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 15, 64)       0           layer_normalization_5[0][0]      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 15, 64)       128         tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 15, 64)       128         tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15, 64)       4160        layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 15, 64)       4160        layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 15, 64)       4160        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 15, 64)       4160        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 15, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 15, 64)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 15, 64)       0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 15, 64)       0           layer_normalization_6[0][0]      \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 15, 64)       128         tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 15, 64)       128         tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 15, 64)       33216       layer_normalization_3[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 15, 64)       33216       layer_normalization_7[0][0]      \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 15, 64)       0           multi_head_attention_4[0][0]     \n",
      "                                                                 multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 15, 64)       0           tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 15, 32)       2080        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 15, 32)       0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 32)           0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           528         global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            17          dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 392,101\n",
      "Trainable params: 392,083\n",
      "Non-trainable params: 18\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('attn_transformer_price_volume_epoch_005_val_0.991.h5', custom_objects = {'Time2Vector':Time2Vector})\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 787.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((64200, 60, 4), (64200, 60, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_price = [] \n",
    "X_test_volume = []\n",
    "\n",
    "for j in tqdm(range(x_test.shape[0]), position = 0, leave = True): \n",
    "    for i in range(seq_len-K-N-120, seq_len-K-N):\n",
    "        X_test_price.append(x_test[j, i:i+N, [1,2,3,4]])  \n",
    "        X_test_volume.append(x_test[j, i:i+N, [5,6,7,8,9]])\n",
    "\n",
    "X_test_price = np.asarray(X_test_price) \n",
    "X_test_volume = np.asarray(X_test_volume) \n",
    "\n",
    "X_test_price = X_test_price.reshape((-1,N,features_price)) \n",
    "X_test_volume = X_test_volume.reshape((-1,N,features_volume))\n",
    "\n",
    "X_test_price.shape, X_test_volume.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535, 120)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = best_model.predict([X_test_price, X_test_volume]) \n",
    "predicted = predicted.reshape((-1,120)) \n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 115086.30it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test_open = x_test[:,:,1] \n",
    "\n",
    "## Adjust predicted prices to be connected with the buy price \n",
    "for i in tqdm(range(predicted.shape[0]), position = 0, leave = True):\n",
    "    buy_price = x_test_open[i,-1] \n",
    "    if predicted[i,0] > buy_price:\n",
    "        diff = predicted[i,0] - buy_price \n",
    "        predicted[i,:] -= diff \n",
    "    elif predicted[i,0] < buy_price:  \n",
    "        diff = buy_price - predicted[i,0] \n",
    "        predicted[i,:] += diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [00:00<00:00, 3867.30it/s]\n"
     ]
    }
   ],
   "source": [
    "buy_quantities = [] \n",
    "sell_times = [] \n",
    "\n",
    "for i in tqdm(range(predicted.shape[0]), position = 0, leave = True): \n",
    "    sell_time = np.argmax(predicted[i,:]) \n",
    "    sell_times.append(sell_time) \n",
    "    buy_price = x_test_open[i,-1] \n",
    "    cnt = 0 \n",
    "    for j in range(120): \n",
    "        if predicted[i,j] >= buy_price:    \n",
    "            cnt += 1 \n",
    "    buy_quantity = cnt/120 \n",
    "    buy_quantities.append(buy_quantity)\n",
    "    \n",
    "submission.iloc[:,1] = buy_quantities \n",
    "submission.iloc[:,2] = sell_times  \n",
    "submission.to_csv('transformers_attention_full_features.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>buy_quantity</th>\n",
       "      <th>sell_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7661</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7662</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7663</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7664</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7665</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>8191</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>8192</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>8193</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>8194</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>8195</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id  buy_quantity  sell_time\n",
       "0         7661      0.966667        105\n",
       "1         7662      0.941667         34\n",
       "2         7663      0.991667         73\n",
       "3         7664      0.183333         15\n",
       "4         7665      0.716667         97\n",
       "..         ...           ...        ...\n",
       "530       8191      0.100000         10\n",
       "531       8192      0.425000          2\n",
       "532       8193      0.950000         71\n",
       "533       8194      0.025000         18\n",
       "534       8195      0.208333         20\n",
       "\n",
       "[535 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
