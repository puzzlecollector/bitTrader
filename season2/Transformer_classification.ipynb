{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bitTrader.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOETjZG4ld2G+oepaJqBXui"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"-uPdtedrgVwG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619162099814,"user_tz":-540,"elapsed":3714,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}},"outputId":"40b82d5f-334d-444c-8b55-eacd70fb3af1"},"source":["import numpy as np \n","import pandas as pd \n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *  \n","from tensorflow.keras.callbacks import *\n","from tqdm import tqdm\n","import time\n","import random\n","import math\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow_probability import distributions as tfd\n","import torch\n","\n","torch.manual_seed(0)\n","np.random.seed(0)\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ga7FHh3WfxpM","executionInfo":{"status":"ok","timestamp":1619162102638,"user_tz":-540,"elapsed":833,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}},"outputId":"23d06132-7fab-4130-fe8c-4e22a6a9469c"},"source":["%cd /content/gdrive/MyDrive/\n","directory = \"./bitTrader\"\n","#import os\n","#os.chdir('/content/gdrive/MyDrive/')\n","#!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNA1YNbTgp4i","executionInfo":{"status":"ok","timestamp":1619162143963,"user_tz":-540,"elapsed":40229,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["train_x_2 = pd.read_csv(directory+'/train_x_df.csv') \n","train_y_2 = pd.read_csv(directory+'/train_y_df.csv') \n","test_x_2 = pd.read_csv(directory+'/test_x_df.csv')\n","submission = pd.read_csv(directory+'/sample_submission.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhtH_yoVhI7n","executionInfo":{"status":"ok","timestamp":1619162153303,"user_tz":-540,"elapsed":849,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["def df2d_to_array3d(df_2d):\n","    feature_size = df_2d.iloc[:,2:].shape[1]\n","    time_size = len(df_2d.time.value_counts())\n","    sample_size = len(df_2d.sample_id.value_counts())\n","    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n","    return array_3d"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-HaCXcshOIO","executionInfo":{"status":"ok","timestamp":1619162155857,"user_tz":-540,"elapsed":1990,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["x_train = df2d_to_array3d(train_x_2) \n","y_train = df2d_to_array3d(train_y_2) \n","x_test = df2d_to_array3d(test_x_2) "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4BcF6rOhWkK","executionInfo":{"status":"ok","timestamp":1619162157629,"user_tz":-540,"elapsed":904,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["def plot_series(x_series, y_series, y_predicted):\n","    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n","    plt.plot(x_series, label = 'input_series')\n","    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n","             y_series, label = 'actual_series') \n","    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n","             y_predicted, label = 'predicted_series') \n","    #plt.axhline(1, c = 'red')\n","    plt.legend()\n","\n","\n","def plot_predicted_series(x_series, y_predicted):\n","    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n","    plt.plot(x_series, label = 'input_series')\n","    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n","             y_predicted, label = 'predicted_series') \n","    #plt.axhline(1, c = 'red')\n","    plt.legend()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8ggtYkQhcGI","executionInfo":{"status":"ok","timestamp":1619162159621,"user_tz":-540,"elapsed":714,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["x_train_close = x_train[:,:,4] \n","y_train_close = y_train[:,:,4] \n","x_test_close = x_test[:,:,4] "],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZVmhcpNhfHE","executionInfo":{"status":"ok","timestamp":1619162161552,"user_tz":-540,"elapsed":1107,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["close_prices = np.concatenate([x_train_close, y_train_close], axis = 1) \n","\n","eps = 1e-8\n","\n","close_prices = np.log(close_prices + eps)\n","\n","x_test_close = np.log(x_test_close + eps)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8ajz1aXhjyz","executionInfo":{"status":"ok","timestamp":1619162190598,"user_tz":-540,"elapsed":27226,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}},"outputId":"9b70563c-f0f8-4a5c-8821-c63ce2510d26"},"source":["### proprocess data\n","K = 120 \n","N = 60 \n","seq_len = 1500 \n","features = 1\n","X = [] \n","Y = [] \n","\n","for j in tqdm(range(close_prices.shape[0]), position = 0, leave = True): \n","    i = 0\n","    while i+N+K < 1500: \n","        X.append(close_prices[j, i:i+N]) \n","        if close_prices[j, i+N+K] > 1.001*close_prices[j, i+N]:\n","          Y.append(1.0)\n","        else:\n","          Y.append(0.0)\n","        #Y.append(close_prices[j, i+N+K]) \n","        i += 1   \n","        \n","        \n","X = np.asarray(X) \n","Y = np.asarray(Y)\n","\n","\n","X = X.reshape((-1,N,features)) \n","Y = Y.reshape((-1,features))\n","X.shape, Y.shape"],"execution_count":11,"outputs":[{"output_type":"stream","text":["100%|██████████| 7661/7661 [00:17<00:00, 437.73it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["((10112520, 60, 1), (10112520, 1))"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"hWhdAsIHh_hZ","executionInfo":{"status":"ok","timestamp":1619162195698,"user_tz":-540,"elapsed":696,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["### define model\n","no_parameters = 3\n","components = 4\n","\n","def nnelu(input):\n","    \"\"\" Computes the Non-Negative Exponential Linear Unit\n","    \"\"\"\n","    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n","\n","def slice_parameter_vectors(parameter_vector):\n","    \"\"\" Returns an unpacked list of paramter vectors.\n","    \"\"\"\n","    return [parameter_vector[:,i*components:(i+1)*components] for i in range(no_parameters)]\n","\n","def gnll_loss(y, parameter_vector):\n","    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n","    \"\"\"\n","    alpha, mu, sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n","    \n","    gm = tfd.MixtureSameFamily(\n","        mixture_distribution=tfd.Categorical(probs=alpha),\n","        components_distribution=tfd.Normal(\n","            loc=mu,       \n","            scale=sigma))\n","    \n","    log_likelihood = gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y\n","    \n","    return -tf.reduce_mean(log_likelihood, axis=-1)\n","\n","tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"9I4n2bBIiCiK","executionInfo":{"status":"ok","timestamp":1619162201151,"user_tz":-540,"elapsed":744,"user":{"displayName":"Kevvvy Kim","photoUrl":"","userId":"05315472711888380072"}}},"source":["def transformer_block(inputs, node, drop_rate, activation): \n","    attn_output = MultiHeadAttention(num_heads = 2, key_dim = node)(inputs, inputs) \n","    attn_output = Dropout(drop_rate)(attn_output) \n","    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output) \n","    ffn_output = Dense(node, activation = activation)(out1) \n","    ffn_output = Dense(node)(ffn_output) \n","    ffn_output = Dropout(drop_rate)(ffn_output)\n","    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output) \n","    return out2\n","    \n","    \n","def build_transformer(node = 64, activation = 'relu', drop_rate = 0.2, num_layers = 3):  \n","    inputs = Input((N, features)) \n","    bn = BatchNormalization()(inputs)\n","    x = Conv1D(node*2, 5, activation = activation)(bn) \n","    x = MaxPooling1D(3)(x) \n","    x = Dropout(drop_rate)(x) \n","    x = Conv1D(node, 5, activation = activation)(x) \n","    x = MaxPooling1D(3)(x) \n","    x = Dropout(drop_rate)(x) \n","    \n","    positions = tf.range(start=0, limit=x.shape[1], delta=1)\n","    positions = Embedding(input_dim = x.shape[1], output_dim = node)(positions) \n","    x = x + positions \n","    \n","    x = transformer_block(x, node, drop_rate, activation) \n","        \n","    x = GlobalMaxPooling1D()(x)\n","    x = Dropout(drop_rate)(x)  \n","\n","    outputs = Dense(1, activation=\"sigmoid\")(x)\n","    model = Model(inputs=inputs, outputs=outputs)\n","    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy'])\n","    \n","    \n","    #alpha_v = Dense(components, activation = 'softmax')(x)\n","    #mu_v = Dense(components)(x) \n","    #sigma_v = Dense(components, activation = 'nnelu')(x)\n","    \n","    #outputs = Concatenate()([alpha_v, mu_v, sigma_v])\n","    \n","    #model = Model(inputs=inputs,outputs=outputs) \n","    #model.compile(loss = gnll_loss, optimizer = 'adam') \n","    return model"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpzZLl08iHhD","outputId":"80e86455-c52e-4bd0-b279-e495c60f97e5"},"source":["model = build_transformer() \n","\n","model_path = 'Transformer_MDN_Close_epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n","learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5)\n","checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n","early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n","\n","\n","history = model.fit(x=X, y=Y, batch_size = 32, epochs = 100, callbacks = [learning_rate_reduction, checkpoint, early_stopping], validation_split = 0.1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","135212/284415 [=============>................] - ETA: 38:28 - loss: 0.6492 - accuracy: 0.6332"],"name":"stdout"}]}]}