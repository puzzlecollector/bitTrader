{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "positional_encoding_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGyMrjHJJsw6",
        "outputId": "9fe6cc20-2d49-4886-cb51-003b65dda8e1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 11 09:21:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GckKUDbTNqDo"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *  \n",
        "from tensorflow.keras.callbacks import *\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow_probability import distributions as tfd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsumnbTnOQUF",
        "outputId": "b434d4f8-2e2a-4cfa-fadd-4e4139da7b48"
      },
      "source": [
        "## season 2 dataframes \n",
        "train_x_2 = pd.read_csv('./drive/MyDrive/bitTrader2/train_x_df.csv')\n",
        "train_y_2 = pd.read_csv('./drive/MyDrive/bitTrader2/train_y_df.csv') \n",
        "test_x_2 = pd.read_csv('./drive/MyDrive/bitTrader2/test_x_df.csv') \n",
        "submission = pd.read_csv('./drive/MyDrive/bitTrader2/sample_submission.csv') \n",
        "\n",
        "train_x_2.shape, train_y_2.shape, test_x_2.shape, submission.shape\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10572180, 12), (919320, 12), (738300, 12), (535, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9tuDL7GPKi4",
        "outputId": "0dc21bb0-9e08-461b-f135-d32455ef960d"
      },
      "source": [
        "def df2d_to_array3d(df_2d):\n",
        "    feature_size = df_2d.iloc[:,2:].shape[1]\n",
        "    time_size = len(df_2d.time.value_counts())\n",
        "    sample_size = len(df_2d.sample_id.value_counts())\n",
        "    array_3d = df_2d.iloc[:,2:].values.reshape([sample_size, time_size, feature_size])\n",
        "    return array_3d\n",
        "\n",
        "\n",
        "x_train = df2d_to_array3d(train_x_2) \n",
        "y_train = df2d_to_array3d(train_y_2) \n",
        "x_test = df2d_to_array3d(test_x_2) \n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7661, 1380, 10), (7661, 120, 10), (535, 1380, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vftix0BPdJg"
      },
      "source": [
        "def plot_series(x_series, y_series, y_predicted):\n",
        "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
        "    plt.plot(x_series, label = 'input_series')\n",
        "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_series)),\n",
        "             y_series, label = 'actual_series') \n",
        "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
        "             y_predicted, label = 'predicted_series') \n",
        "    #plt.axhline(1, c = 'red')\n",
        "    plt.legend()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrKOLx1QQ8pl"
      },
      "source": [
        "def plot_predicted_series(x_series, y_predicted):\n",
        "    #입력 series와 출력 series를 연속적으로 연결하여 시각적으로 보여주는 코드 입니다.\n",
        "    plt.plot(x_series, label = 'input_series')\n",
        "    plt.plot(np.arange(len(x_series), len(x_series)+len(y_predicted)),\n",
        "             y_predicted, label = 'predicted_series') \n",
        "    #plt.axhline(1, c = 'red')\n",
        "    plt.legend()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAdahkFRQ98B",
        "outputId": "3deb8e0f-b618-4f7a-e0eb-31e7dcf9476f"
      },
      "source": [
        "full_df = np.concatenate([x_train, y_train], axis = 1) \n",
        "full_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7661, 1500, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r4wUMDNvhWW",
        "outputId": "cbfdf4ea-fafe-4a86-d77a-ed03a23ce4ee"
      },
      "source": [
        "price_data = full_df[:100,:,[1,2,3,4]] \n",
        "volume_data = full_df[:100,:,[5,6,7,8,9]] \n",
        "id_data = full_df[:100,0,0] \n",
        "\n",
        "price_data.shape, volume_data.shape, id_data.shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 1500, 4), (100, 1500, 5), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRIdISQNxZVj",
        "outputId": "e071a4fc-215e-4330-9278-aa14cced6ff9"
      },
      "source": [
        "id_data"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9., 9., 4., 0., 7., 4., 6., 0., 0., 9., 4., 6., 4., 4., 0., 7., 8.,\n",
              "       9., 9., 5., 1., 9., 6., 4., 9., 5., 4., 9., 9., 7., 0., 4., 4., 6.,\n",
              "       0., 7., 6., 9., 0., 6., 6., 8., 7., 8., 4., 5., 4., 7., 8., 7., 6.,\n",
              "       4., 6., 8., 4., 7., 9., 0., 6., 0., 3., 4., 0., 8., 0., 6., 7., 1.,\n",
              "       4., 7., 8., 6., 4., 5., 6., 6., 5., 7., 0., 8., 8., 9., 9., 6., 1.,\n",
              "       5., 7., 6., 9., 0., 7., 0., 4., 7., 9., 1., 5., 5., 8., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lZ-cpKTv01V",
        "outputId": "e485d449-21f0-416b-8abb-4b299ad24e59"
      },
      "source": [
        "# min max scale volume data \n",
        "for i in tqdm(range(volume_data.shape[0])): \n",
        "  for j in range(volume_data.shape[2]): \n",
        "    min_val = np.min(volume_data[i,:,j]) \n",
        "    max_val = np.max(volume_data[i,:,j]) \n",
        "    volume_data[i,:,j] = (volume_data[i,:,j] - min_val) / (max_val - min_val)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 8994.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL4oBB67REaR",
        "outputId": "628dbc37-17c3-43fc-9484-bb439ece4d70"
      },
      "source": [
        "K = 120 \n",
        "N = 30  \n",
        "seq_len = 1500 \n",
        "features_price = 4 \n",
        "features_volume = 5 \n",
        "features_id = 1 \n",
        "X_price = np.zeros(((seq_len-N-K)*price_data.shape[0],N,features_price)) \n",
        "X_volume = np.zeros(((seq_len-N-K)*price_data.shape[0],N,features_volume)) \n",
        "X_id = np.zeros(((seq_len-N-K)*price_data.shape[0]))\n",
        "Y = np.zeros(((seq_len-N-K)*price_data.shape[0]))\n",
        "\n",
        "\n",
        "cnt = 0 \n",
        "for j in tqdm(range(price_data.shape[0]), position = 0, leave = True): \n",
        "  i = 0 \n",
        "  while i+N+K < seq_len: \n",
        "    X_price[cnt,:,:] = price_data[j,i:i+N,:]\n",
        "    X_volume[cnt,:,:] = volume_data[j,i:i+N,:] \n",
        "    X_id[cnt] = id_data[j]\n",
        "    Y[cnt] = price_data[j,i+N+K,0] \n",
        "    i += 1 \n",
        "    cnt += 1 \n",
        "\n",
        "X_price.shape, X_volume.shape, X_id.shape, Y.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 218.36it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((135000, 30, 4), (135000, 30, 5), (135000,), (135000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3kw6jMF3xbc",
        "outputId": "c59711cb-dda7-4693-9196-1760273917c8"
      },
      "source": [
        "X_id.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(135000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJHelD8wRMik"
      },
      "source": [
        "class Time2Vector(Layer):\n",
        "    def __init__(self, seq_len, **kwargs):\n",
        "        super(Time2Vector, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
        "        self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                              shape=(int(self.seq_len),),\n",
        "                                              initializer='glorot_uniform',\n",
        "                                              trainable=True)\n",
        "    \n",
        "        self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                           shape=(int(self.seq_len),),\n",
        "                                           initializer='glorot_uniform',\n",
        "                                           trainable=True)\n",
        "    \n",
        "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                                shape=(int(self.seq_len),),\n",
        "                                                initializer='glorot_uniform',\n",
        "                                                trainable=True)\n",
        "\n",
        "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                             shape=(int(self.seq_len),),\n",
        "                                             initializer='glorot_uniform',\n",
        "                                             trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        '''Calculate linear and periodic time features'''\n",
        "        x = tf.math.reduce_mean(x[:,:,:], axis=-1) \n",
        "        time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
        "        time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
        "    \n",
        "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
        "        return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
        "   \n",
        "    def get_config(self): # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'seq_len': self.seq_len})\n",
        "        return config\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOwXCG_6JbSf"
      },
      "source": [
        "def positional_encoding(max_position, d_model, min_freq=1e-4):\n",
        "    position = tf.range(max_position, dtype=tf.float32)\n",
        "    mask = tf.range(d_model)\n",
        "    sin_mask = tf.cast(mask%2, tf.float32)\n",
        "    cos_mask = 1-sin_mask\n",
        "    exponent = 2*(mask//2)\n",
        "    exponent = tf.cast(exponent, tf.float32)/tf.cast(d_model, tf.float32)\n",
        "    freqs = min_freq**exponent\n",
        "    angles = tf.einsum('i,j->ij', position, freqs)\n",
        "    pos_enc = tf.math.cos(angles)*cos_mask + tf.math.sin(angles)*sin_mask\n",
        "    return pos_enc\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mK1Spa_xzDg"
      },
      "source": [
        "epsilon = 1e-10 # some very small number \n",
        "\n",
        "def transformer_block(inputs, node, drop_rate, activation): \n",
        "    attn_output = MultiHeadAttention(num_heads = 4, key_dim = node)(inputs, inputs) \n",
        "    attn_output = Dropout(drop_rate)(attn_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "    ffn_output = Dense(node, activation = activation)(out1)\n",
        "    ffn_output = Dense(node)(ffn_output)\n",
        "    ffn_output = Dropout(drop_rate)(ffn_output)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn_output) \n",
        "    return out2 \n",
        "\n",
        "def transformer_model(inputs, id_inputs, node=64, activation='relu', drop_rate=0.2, num_layers=3): \n",
        "    time_embedding = Time2Vector(N)\n",
        "    bn = BatchNormalization()(inputs)\n",
        "    x = time_embedding(bn)\n",
        "    x = Concatenate()([bn, x])\n",
        "    x = Conv1D(node, 5, activation=activation, padding='same')(x)\n",
        "    x = MaxPooling1D(3)(x) \n",
        "    x = Conv1D(node*3, 5, activation=activation, padding='same')(x)\n",
        "    x = MaxPooling1D(3)(x)\n",
        "    x = Dropout(drop_rate)(x)\n",
        "    positions = positional_encoding(x.shape[1], node*3)\n",
        "    id_info = Embedding(input_dim = 10, output_dim = node*3)(id_inputs)\n",
        "    x = x + positions + id_info    \n",
        "    for i in range(num_layers): \n",
        "        x = transformer_block(x, node*3, drop_rate, activation) \n",
        "        x = BatchNormalization()(x) \n",
        "    x = GlobalAveragePooling1D()(x) \n",
        "    return x\n",
        "\n",
        "def build_model(node=64, activation='relu', drop_rate=0.2, num_layers=3): \n",
        "    price_inputs = Input((N, features_price))\n",
        "    volume_inputs = Input((N, features_volume)) \n",
        "    id_inputs = Input((features_id))\n",
        "\n",
        "    x_p = transformer_model(price_inputs, id_inputs) \n",
        "    x_v = transformer_model(volume_inputs, id_inputs)\n",
        "\n",
        "    x = Concatenate()([x_p, x_v])\n",
        "    x = Dense(x_p.shape[-1], activation = 'relu')(x) \n",
        "    x = BatchNormalization()(x) \n",
        "    x = Dense(x_p.shape[-1]/3, activation = 'relu')(x) \n",
        "    x = BatchNormalization()(x) \n",
        "    x = Dense(1, activation = 'relu')(x) \n",
        "    model = Model(inputs=[price_inputs, volume_inputs, id_inputs], outputs=x) \n",
        "    model.compile(loss='mape',optimizer='adam',metrics=['mae','mse','mape'])\n",
        "    return model"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91vHoyMtx4tv"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "S4rTi0sqx6EI",
        "outputId": "1d12a0cd-f2b8-47bc-dac7-607fae7bba5f"
      },
      "source": [
        "model_path = 'transformer_price_volume_epoch_{epoch:03d}_val_{val_loss:.3f}.h5'\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5)\n",
        "checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
        "\n",
        "\n",
        "history = model.fit([X_price, X_volume, X_id], \n",
        "                     Y, \n",
        "                     batch_size = 16, \n",
        "                     epochs = 50, \n",
        "                     callbacks = [learning_rate_reduction, checkpoint], \n",
        "                     validation_split = 0.1)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 520/7594 [=>............................] - ETA: 2:10 - loss: 100.0000 - mae: 1.0018 - mse: 1.0051 - mape: 100.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-b9c40c6280ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                      \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlearning_rate_reduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                      validation_split = 0.1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m     \u001b[0mcache_key_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_key_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3139\u001b[0m     \u001b[0;31m# building (e.g. accessing different variables from different devices) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m     \u001b[0;31m# so requires retracing for each device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3141\u001b[0;31m     \u001b[0mstrategy_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3142\u001b[0m     uses_distribution_strategy = (\n\u001b[1;32m   3143\u001b[0m         \u001b[0mstrategy_stack\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_distribution_strategy_stack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5161\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5162\u001b[0m     \u001b[0;34m\"\"\"A stack to maintain distribution strategy context for each thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5163\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_distribution_strategy_stack\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5164\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7WhoWFL84Ec"
      },
      "source": [
        "# Make Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdv5kB779Ixf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gYBnpUz9Jfs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8JYphA9Jdr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yR1SLrH9JYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}